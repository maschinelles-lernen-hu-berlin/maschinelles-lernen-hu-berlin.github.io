<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Lehrstuhl Maschinelles Lernen</title><link>https://example.com/</link><atom:link href="https://example.com/index.xml" rel="self" type="application/rss+xml"/><description>Lehrstuhl Maschinelles Lernen</description><generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Sat, 01 Jun 2030 13:00:00 +0000</lastBuildDate><image><url>https://example.com/media/logo_hueebd31b28f82aeb63357b594dab7cdfb_24654_300x300_fit_lanczos_3.png</url><title>Lehrstuhl Maschinelles Lernen</title><link>https://example.com/</link></image><item><title>Statistik und Data Science</title><link>https://example.com/course/2022sose/statisik/</link><pubDate>Fri, 01 Apr 2022 00:00:00 +0000</pubDate><guid>https://example.com/course/2022sose/statisik/</guid><description>&lt;p>Pflichtlehre im 4. Semester des Bachelor-Studiums.&lt;/p>
&lt;h1 id="lecture-1">Lecture 1&lt;/h1>
&lt;p>content&lt;/p>
&lt;h1 id="lecture-2">Lecture 2&lt;/h1>
&lt;p>content&lt;/p></description></item><item><title>Introduction to Natural Language Processing</title><link>https://example.com/course/2021wise/intro_nlp/</link><pubDate>Fri, 01 Oct 2021 00:00:00 +0000</pubDate><guid>https://example.com/course/2021wise/intro_nlp/</guid><description>&lt;p>In the master course, we give an introduction to Natural Language Processing and do lots of hands-on deep learning in Python and PyTorch. It consist of a lecture and a practical exercise.&lt;/p>
&lt;h1 id="lecture-1">Lecture 1&lt;/h1>
&lt;p>content&lt;/p>
&lt;h1 id="lecture-2">Lecture 2&lt;/h1>
&lt;p>content&lt;/p></description></item><item><title>Introduction to Natural Language Processing</title><link>https://example.com/course/2021sose/intro_nlp/</link><pubDate>Thu, 01 Apr 2021 00:00:00 +0000</pubDate><guid>https://example.com/course/2021sose/intro_nlp/</guid><description>&lt;p>In the master course, we give an introduction to Natural Language Processing and do lots of hands-on deep learning in Python and PyTorch. It consist of a lecture and a practical exercise.&lt;/p>
&lt;h1 id="lecture-1">Lecture 1&lt;/h1>
&lt;p>content&lt;/p>
&lt;h1 id="lecture-2">Lecture 2&lt;/h1>
&lt;p>content&lt;/p></description></item><item><title>Example Event</title><link>https://example.com/event/example/</link><pubDate>Sat, 01 Jun 2030 13:00:00 +0000</pubDate><guid>https://example.com/event/example/</guid><description>&lt;p>Slides can be added in a few ways:&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Create&lt;/strong> slides using Wowchemy&amp;rsquo;s &lt;a href="https://wowchemy.com/docs/managing-content/#create-slides" target="_blank" rel="noopener">&lt;em>Slides&lt;/em>&lt;/a> feature and link using &lt;code>slides&lt;/code> parameter in the front matter of the talk file&lt;/li>
&lt;li>&lt;strong>Upload&lt;/strong> an existing slide deck to &lt;code>static/&lt;/code> and link using &lt;code>url_slides&lt;/code> parameter in the front matter of the talk file&lt;/li>
&lt;li>&lt;strong>Embed&lt;/strong> your slides (e.g. Google Slides) or presentation video on this page using &lt;a href="https://wowchemy.com/docs/writing-markdown-latex/" target="_blank" rel="noopener">shortcodes&lt;/a>.&lt;/li>
&lt;/ul>
&lt;p>Further event details, including page elements such as image galleries, can be added to the body of this page.&lt;/p></description></item><item><title>Joint Zero-Shot Learning for Sequence Labeling and Text Classification</title><link>https://example.com/theses/jonas-golde-2021/</link><pubDate>Wed, 13 Apr 2022 00:00:00 +0000</pubDate><guid>https://example.com/theses/jonas-golde-2021/</guid><description>&lt;p>TARS uses a premise-hypothesis data input structure to technically transform every text classification task into a binary label
space compared to previous models. This input structure enables TARS to train the
same model for different corpora and eliminates the need to add a custom linear layer for
each tag space. Further, this layout leverages the integration of semantic information
from the label of a concrete data point.&lt;/p></description></item><item><title>New startup!</title><link>https://example.com/news/2022-startup-dotch/</link><pubDate>Sat, 01 Jan 2022 00:00:00 +0000</pubDate><guid>https://example.com/news/2022-startup-dotch/</guid><description>&lt;p>Launch of dotch, a startup for zero waste packaging, mentored and financed via the EXIST programme!&lt;/p>
&lt;p>Launch of dotch, a startup for zero waste packaging, mentored and financed via the EXIST programme!&lt;/p></description></item><item><title>New release - Flair version 0.10!</title><link>https://example.com/news/2021-flair-0.10/</link><pubDate>Thu, 18 Nov 2021 00:00:00 +0000</pubDate><guid>https://example.com/news/2021-flair-0.10/</guid><description>&lt;p>Flair (v0.10) released, adding many new features!&lt;/p></description></item><item><title>Two new startups!</title><link>https://example.com/news/2021-startups-cluster-judict/</link><pubDate>Mon, 01 Nov 2021 00:00:00 +0000</pubDate><guid>https://example.com/news/2021-startups-cluster-judict/</guid><description>&lt;p>Launch of (1) Cluster, a startup for new journalism + NLP, und (2) judict, a startup for legal data + NLP. Both mentored and financed via EXIST!&lt;/p>
&lt;p>Launch of (1) Cluster, a startup for new journalism + NLP, und (2) judict, a startup for legal data + NLP. Both mentored and financed via EXIST!&lt;/p></description></item><item><title>New startup!</title><link>https://example.com/news/2021-startup-kuwala/</link><pubDate>Fri, 01 Oct 2021 00:00:00 +0000</pubDate><guid>https://example.com/news/2021-startup-kuwala/</guid><description>&lt;p>Launch of Kuwala, a startup for open source data integration, mentored and financed via the EXIST programme!&lt;/p>
&lt;p>Launch of Kuwala, a startup for open source data integration, mentored and financed via the EXIST programme!&lt;/p></description></item><item><title>Modeling Neurogenesis for Continuous Learning</title><link>https://example.com/project/2021-neurogenesis/</link><pubDate>Mon, 06 Sep 2021 00:00:00 +0000</pubDate><guid>https://example.com/project/2021-neurogenesis/</guid><description>&lt;p>DFG-funded project &amp;ldquo;Modeling Neurogenesis for Continuous Learning&amp;rdquo; in the Science of Intelligence (SCIoI) cluster of excellence approved!&lt;/p></description></item><item><title>New DFG research grant!</title><link>https://example.com/news/2021-neurogenesis/</link><pubDate>Mon, 06 Sep 2021 00:00:00 +0000</pubDate><guid>https://example.com/news/2021-neurogenesis/</guid><description>&lt;p>DFG-funded project &amp;ldquo;Modeling Neurogenesis for Continuous Learning&amp;rdquo; in the Science of Intelligence cluster of excellence approved!&lt;/p>
&lt;p>The project will focus on &amp;hellip;&lt;/p></description></item><item><title>New release - Flair version 0.9!</title><link>https://example.com/news/2021-flair-0.9/</link><pubDate>Mon, 30 Aug 2021 00:00:00 +0000</pubDate><guid>https://example.com/news/2021-flair-0.9/</guid><description>&lt;p>Flair (v0.9) released, adding speed and many new NLP tasks to Flair!&lt;/p>
&lt;p>The project will focus on &amp;hellip;&lt;/p>
&lt;p>23.08.2021 - Research grant: DFG-funded project &amp;ldquo;Efficient Model Learning from Data with Partially Incorrect Labels&amp;rdquo; in the Science of Intelligence (SCIoI) cluster of excellence approved! Positions for PhD candidates available from October 2022!&lt;/p></description></item><item><title>Efficient Model Learning from Data with Partially Incorrect Labels</title><link>https://example.com/project/2021-noisy-labels/</link><pubDate>Mon, 23 Aug 2021 00:00:00 +0000</pubDate><guid>https://example.com/project/2021-noisy-labels/</guid><description>&lt;p>DFG-funded project &amp;ldquo;Efficient Model Learning from Data with Partially Incorrect Labels&amp;rdquo; in the Science of Intelligence (SCIoI) cluster of excellence approved!&lt;/p></description></item><item><title>New DFG research grant!</title><link>https://example.com/news/2021-noisy-labels/</link><pubDate>Mon, 23 Aug 2021 00:00:00 +0000</pubDate><guid>https://example.com/news/2021-noisy-labels/</guid><description>&lt;p>DFG-funded project &amp;ldquo;Efficient Model Learning from Data with Partially Incorrect Labels&amp;rdquo; in the Science of Intelligence (SCIoI) cluster of excellence approved!&lt;/p>
&lt;p>The project will focus on &amp;hellip;&lt;/p>
&lt;p>23.08.2021 - Research grant: DFG-funded project &amp;ldquo;Efficient Model Learning from Data with Partially Incorrect Labels&amp;rdquo; in the Science of Intelligence (SCIoI) cluster of excellence approved! Positions for PhD candidates available from October 2022!&lt;/p></description></item><item><title>New release - Flair version 0.8!</title><link>https://example.com/news/2021-flair-0.8/</link><pubDate>Mon, 23 Aug 2021 00:00:00 +0000</pubDate><guid>https://example.com/news/2021-flair-0.8/</guid><description>&lt;p>Flair (v0.8) released, adding our powerful FLERT approach and HuggingFace model hub support to Flair!&lt;/p></description></item><item><title>New BMWi research grant!</title><link>https://example.com/news/2021-zim-sebira/</link><pubDate>Sun, 01 Aug 2021 00:00:00 +0000</pubDate><guid>https://example.com/news/2021-zim-sebira/</guid><description>&lt;p>The BMWi-funded project &amp;ldquo;ML-SEBIRA&amp;rdquo; with industry partner neofonie starts today!&lt;/p>
&lt;p>The project will focus on &amp;hellip;&lt;/p></description></item><item><title>Word Representations for Information Retrievel</title><link>https://example.com/project/zim-sebira/</link><pubDate>Sun, 01 Aug 2021 00:00:00 +0000</pubDate><guid>https://example.com/project/zim-sebira/</guid><description>&lt;p>The BMWi-funded project &amp;ldquo;ML-SEBIRA&amp;rdquo; (Semantische Begriffsanalyse fÃ¼r das Information Retrieval) with industry partner neofonie starts today!&lt;/p>
&lt;p>The project will focus on &amp;hellip;&lt;/p></description></item><item><title>Paper accepted!</title><link>https://example.com/news/2021-acl-paper/</link><pubDate>Thu, 01 Jul 2021 00:00:00 +0000</pubDate><guid>https://example.com/news/2021-acl-paper/</guid><description>&lt;p>Full paper on early predator detection accepted to ACL 2021!&lt;/p>
&lt;p>The project will focus on &amp;hellip;&lt;/p></description></item><item><title>Eidetic Representations of Natural Lanuage</title><link>https://example.com/project/dfg-emmy-noether/</link><pubDate>Sat, 01 May 2021 00:00:00 +0000</pubDate><guid>https://example.com/project/dfg-emmy-noether/</guid><description>&lt;p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.&lt;/p>
&lt;p>Nullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.&lt;/p>
&lt;p>Cras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.&lt;/p>
&lt;p>Suspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.&lt;/p>
&lt;p>Aliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.&lt;/p></description></item><item><title>Major new DFG research grant!</title><link>https://example.com/news/2021-emmy-noether/</link><pubDate>Sat, 01 May 2021 00:00:00 +0000</pubDate><guid>https://example.com/news/2021-emmy-noether/</guid><description>&lt;p>The DFG-funded project &amp;ldquo;Eidetische ReprÃ¤sentationen natÃ¼rlicher Sprache&amp;rdquo; starts today. This is a massively funded 6-year project looking to advance the state of the art in neural language modeling (BERT, GPT-3).&lt;/p>
&lt;p>See the project page for more information.&lt;/p></description></item><item><title>Neural Representations for Lifelong Learning</title><link>https://example.com/project/2021-lifelonglearning/</link><pubDate>Sat, 01 May 2021 00:00:00 +0000</pubDate><guid>https://example.com/project/2021-lifelonglearning/</guid><description>&lt;p>The DFG-funded project &amp;ldquo;Neural Representations for Lifelong Learning&amp;rdquo; in the Science of Intelligence cluster of excellence starts today!&lt;/p></description></item><item><title>New DFG research grant!</title><link>https://example.com/news/2021-lifelonglearning/</link><pubDate>Sat, 01 May 2021 00:00:00 +0000</pubDate><guid>https://example.com/news/2021-lifelonglearning/</guid><description>&lt;p>The DFG-funded project &amp;ldquo;Neural Representations for Lifelong Learning&amp;rdquo; in the Science of Intelligence cluster of excellence starts today!&lt;/p>
&lt;p>The project will focus on &amp;hellip;&lt;/p></description></item><item><title>Efficient Adaptation for Neuronal Question Answering</title><link>https://example.com/project/zim-ena/</link><pubDate>Thu, 01 Apr 2021 00:00:00 +0000</pubDate><guid>https://example.com/project/zim-ena/</guid><description>&lt;p>The BMWi-funded project &amp;ldquo;ML-ENA&amp;rdquo; (Effiziente lndividualisierung fÃ¼r Neuronales Question Answering) with industry partner deepset starts today!&lt;/p></description></item><item><title>New BMWi research grant!</title><link>https://example.com/news/2021-zim-ena/</link><pubDate>Thu, 01 Apr 2021 00:00:00 +0000</pubDate><guid>https://example.com/news/2021-zim-ena/</guid><description>&lt;p>The BMWi-funded project &amp;ldquo;ML-ENA&amp;rdquo; with industry partner deepset starts today!&lt;/p>
&lt;p>The project will focus on &amp;hellip;&lt;/p></description></item><item><title>AI Marketteer</title><link>https://example.com/project/ibb-marketeer/</link><pubDate>Mon, 01 Mar 2021 00:00:00 +0000</pubDate><guid>https://example.com/project/ibb-marketeer/</guid><description>&lt;p>The IBB-funded project &amp;ldquo;AI Marketteer&amp;rdquo; with industry partners ubermetrics and Webtrekk starts today!&lt;/p></description></item><item><title>FLAIR: An Easy-to-Use Framework for State-of-the-Art NLP</title><link>https://example.com/publications/2019-flair-framework/</link><pubDate>Sat, 01 Jun 2019 00:00:00 +0000</pubDate><guid>https://example.com/publications/2019-flair-framework/</guid><description>&lt;p>We present FLAIR, an NLP framework designed to facilitate training and distribution of state-of-the-art sequence labeling, text classification and language models. The core idea of the framework is to present a simple, unified interface for conceptually very different types of word and document embeddings. This effectively hides all embedding-specific engineering complexity and allows researchers to âmix and matchâ various embeddings with little effort. The framework also implements standard model training and hyperparameter selection routines, as well as a data fetching module that can download publicly available NLP datasets and convert them into data structures for quick set up of experiments. Finally, FLAIR also ships with a âmodel zooâ of pre-trained models to allow researchers to use state-of-the-art NLP models in their applications. This paper gives an overview of the framework and its functionality. The framework is available on GitHub at &lt;a href="https://github.com/flairNLP/flair" target="_blank" rel="noopener">https://github.com/flairNLP/flair&lt;/a>.&lt;/p></description></item><item><title>Contextual String Embeddings for Sequence Labeling</title><link>https://example.com/publications/2018-contextual-string-embeddings/</link><pubDate>Wed, 01 Aug 2018 00:00:00 +0000</pubDate><guid>https://example.com/publications/2018-contextual-string-embeddings/</guid><description>&lt;p>Recent advances in language modeling using recurrent neural networks have made it viable to model language as distributions over characters. By learning to predict the next character on the basis of previous characters, such models have been shown to automatically internalize linguistic concepts such as words, sentences, subclauses and even sentiment. In this paper, we propose to leverage the internal states of a trained character language model to produce a novel type of word embedding which we refer to as contextual string embeddings. Our proposed embeddings have the distinct properties that they (a) are trained without any explicit notion of words and thus fundamentally model words as sequences of characters, and (b) are contextualized by their surrounding text, meaning that the same word will have different embeddings depending on its contextual use. We conduct a comparative evaluation against previous embeddings and find that our embeddings are highly useful for downstream tasks: across four classic sequence labeling tasks we consistently outperform the previous state-of-the-art. In particular, we significantly outperform previous work on English and German named entity recognition (NER), allowing us to report new state-of-the-art F1-scores on the CoNLL03 shared task. We release all code and pre-trained language models in a simple-to-use framework to the research community, to enable reproduction of these experiments and application of our proposed embeddings to other tasks: &lt;a href="https://github.com/zalandoresearch/flair" target="_blank" rel="noopener">https://github.com/zalandoresearch/flair&lt;/a>&lt;/p></description></item><item><title/><link>https://example.com/admin/config.yml</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://example.com/admin/config.yml</guid><description/></item><item><title/><link>https://example.com/contact/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://example.com/contact/</guid><description/></item><item><title/><link>https://example.com/people/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://example.com/people/</guid><description/></item><item><title/><link>https://example.com/research/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://example.com/research/</guid><description/></item></channel></rss>